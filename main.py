# main.py
import os, re, json, tempfile, logging, subprocess, requests
from typing import List, Dict, Optional, Tuple
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from google.oauth2 import service_account
from googleapiclient.discovery import build
from google.auth.transport.requests import Request as GoogleAuthRequest
from openai import OpenAI

logging.basicConfig(level=logging.INFO)

# ========== ENV ==========
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GCRED_PATH     = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
if not OPENAI_API_KEY:
    raise RuntimeError("‚ùå OPENAI_API_KEY not set.")
if not GCRED_PATH or not os.path.exists(GCRED_PATH):
    raise RuntimeError("‚ùå GOOGLE_APPLICATION_CREDENTIALS path is invalid.")

client = OpenAI(api_key=OPENAI_API_KEY)

# ========== APP ==========
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# ========== CONSTANTS ==========
JSON_START = "<<<SCORES_9_JSON_START>>>"
JSON_END   = "<<<SCORES_9_JSON_END>>>"

# ========== HELPERS ==========
def clean_transcript(text: str) -> str:
    text = re.sub(r"\\an\d+\\?.*?", "", text)
    text = re.sub(r"[-‚Äì‚Äî_=*#{}<>[\]\"'`|]", "", text)
    text = re.sub(r"\s{2,}", " ", text)
    text = re.sub(r"\n{2,}", "\n", text)
    text = re.sub(r"\d{2,}[:.]\d{2,}[:.]\d{2,}", "", text)
    return text.strip()

def download_mp3_from_drive(file_id: str) -> str:
    logging.info(f"üì• Downloading MP3 from Google Drive: {file_id}")
    creds = service_account.Credentials.from_service_account_file(
        GCRED_PATH, scopes=["https://www.googleapis.com/auth/drive.readonly"]
    )
    creds.refresh(GoogleAuthRequest())
    drive_service = build("drive", "v3", credentials=creds)
    meta = drive_service.files().get(fileId=file_id, fields="name").execute()
    base = os.path.splitext(meta["name"])[0]

    url = f"https://www.googleapis.com/drive/v3/files/{file_id}?alt=media"
    headers = {"Authorization": f"Bearer {creds.token}"}
    r = requests.get(url, headers=headers, timeout=120)
    if r.status_code != 200:
        raise RuntimeError(f"Failed to download MP3: {r.status_code} - {r.text}")

    mp3_path = os.path.join(tempfile.gettempdir(), base + ".mp3")
    with open(mp3_path, "wb") as f:
        f.write(r.content)
    return mp3_path

def split_audio(mp3_path: str, chunk_seconds: int = 600) -> List[str]:
    logging.info("üî™ Splitting audio into chunks...")
    outdir = tempfile.mkdtemp()
    pattern = os.path.join(outdir, "chunk_%03d.mp3")
    try:
        subprocess.run(
            [
                "ffmpeg", "-y", "-i", mp3_path, "-f", "segment",
                "-segment_time", str(chunk_seconds),
                "-ar", "16000", "-ac", "1", "-vn",
                "-codec:a", "libmp3lame",
                pattern,
            ],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )
    except subprocess.CalledProcessError as e:
        logging.error("‚ùå FFmpeg splitting failed: %s", e.stderr.decode("utf-8", errors="ignore"))
        raise RuntimeError("FFmpeg splitting failed")

    chunks = sorted(os.path.join(outdir, f) for f in os.listdir(outdir) if f.endswith(".mp3"))
    if not chunks:
        raise RuntimeError("No chunks produced by ffmpeg.")
    return chunks

def transcribe_audio(mp3_path: str) -> str:
    logging.info(f"üéß Transcribing audio: {mp3_path}")
    with open(mp3_path, "rb") as fh:
        tr = client.audio.transcriptions.create(
            model="whisper-1", file=fh, response_format="text", language="en"
        )
    return tr.strip()

# ========== REPORT GEN ==========
def generate_openai_report(full_transcript: str) -> str:
    """
    Human-readable report WITH the Legacy 9-Parameter Scorecard (numbers),
    then a machine-readable JSON block between markers for reliable parsing.
    """
    logging.info("üìù Generating OpenAI CRM report...")
    prompt = f"""
üìû [CRM Call Audit Evaluation ‚Äì First-Time Inquiry Call]

You are a senior customer experience auditor reviewing how a CRM executive handled a first-time inquiry call. Analyze this transcript:

{full_transcript}

Your job is to assess:

1. What kind of customer this was (e.g., Price-sensitive, Confused, Serious buyer, Skeptical, Just Exploring)
2. Whether the CRM delivered a confident, informative pitch.
3. If all the customer's questions and objections were handled properly.
4. Whether the lead was moved forward effectively.

--- 

1) **Customer Type & Intent:**
   - Identify the type and cite clues.

2) **Call Opening & Tone Matching:**
   - Was greeting professional/warm?
   - Was tone confident and aligned with customer?
   - Did the CRM actively listen without interrupting?
   - Score: __/10

3) **CRM Pitch & Communication Quality:**
   - Qualifying questions asked?
   - Clear brand/service intro?
   - Key USPs conveyed (customization, natural look, celebs, etc.)?
   - Guided to clear next step?
   - Score: __/10

4) **Questions & Objection Handling:**
   - Which questions/objections?
   - Were they handled confidently?
   - Score: __/10

5) **Missed Opportunities or Gaps:**
   - What was under-explained or missed?

6) **Call Outcome:**
   - Consultation booked? If not, what next step?
   - Follow-up planned?
   - ‚úî Call Status: Booked / Follow-up / Undecided / Not Interested

7) **Customer Tag (Pick One):**
   Price-sensitive | Confused/Over-researching | Serious Buyer | Just Exploring | Referral/Follower | Skeptical/Fearful

8) **Action Required (Pick One):**
   No Action | Minor Feedback | Coaching Required | Retraining Needed | Escalate

---

‚úÖ **Final Verdict & Recommendation:** Concise next steps for CRM and lead.

---

üìä **Legacy 9-Parameter Scorecard (fill REAL numbers, keep EXACT labels):**
- Professional Greeting & Introduction Score: __/15
- Active Listening & Empathy Score: __/15
- Understanding Customer‚Äôs Needs Score: __/10
- Product/Service Explanation Score: __/10
- Personalization & Lifestyle Suitability Score: __/10
- Handling Objections & Answering Queries Score: __/10
- Pricing & Value Communication Score: __/10
- Trust & Confidence Building Score: __/10
- Call Closure & Next Step Commitment Score: __/10

RULES:
- Replace every "__" with integers.
- Keep labels and "Score:" pattern so an automated parser can read it.

---
IMPORTANT: After finishing the human-readable report above,
append on a NEW line ONLY this machine-readable JSON (no extra words, no code fences)
between these exact markers:

{JSON_START}
{{ "greeting": <int>, "listening": <int>, "understanding_needs": <int>, "product_explanation": <int>, "personalization": <int>, "objection_handling": <int>, "pricing_communication": <int>, "trust_building": <int>, "call_closure": <int> }}
{JSON_END}
"""
    resp = client.chat.completions.create(
        model="gpt-4",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=2400,
        temperature=0.2,
    )
    return resp.choices[0].message.content.strip()

def extract_json_and_strip(report_text: str) -> Tuple[Optional[Dict[str,int]], str]:
    """
    Extract the JSON between markers; return (scores_dict, cleaned_report_without_json).
    If extraction fails, scores_dict=None and report_text is returned unchanged.
    """
    try:
        start = report_text.index(JSON_START) + len(JSON_START)
        end   = report_text.index(JSON_END, start)
        json_str = report_text[start:end].strip()
        data = json.loads(json_str)

        # Remove the entire JSON block with markers from the human report
        cleaned = report_text[:report_text.index(JSON_START)].rstrip()
        return (
            {
                "greeting": int(data.get("greeting", 0)),
                "listening": int(data.get("listening", 0)),
                "understanding_needs": int(data.get("understanding_needs", 0)),
                "product_explanation": int(data.get("product_explanation", 0)),
                "personalization": int(data.get("personalization", 0)),
                "objection_handling": int(data.get("objection_handling", 0)),
                "pricing_communication": int(data.get("pricing_communication", 0)),
                "trust_building": int(data.get("trust_building", 0)),
                "call_closure": int(data.get("call_closure", 0)),
            },
            cleaned,
        )
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è JSON block extraction failed, will fallback to regex. {e}")
        return None, report_text

# Tolerant regex fallback for the 9 legacy params
def parse_scores_from_report(report_text: str) -> Dict[str, int]:
    def grab(label_regex: str) -> int:
        m = re.search(
            label_regex + r".{0,200}?Score\s*[:\-]?\s*(\d{1,2})\s*/\s*\d{1,2}",
            report_text,
            re.IGNORECASE | re.DOTALL,
        )
        return int(m.group(1)) if m else 0

    scores = {
        "greeting":               grab(r"Professional\s+Greeting\s*&\s*Introduction"),
        "listening":              grab(r"Active\s+Listening\s*&\s*Empathy"),
        "understanding_needs":    grab(r"Understanding\s+Customer[‚Äô']?s\s+Needs"),
        "product_explanation":    grab(r"Product/?Service\s+Explanation"),
        "personalization":        grab(r"Personalization\s*&\s*Lifestyle(?:\s*Suitability)?"),
        "objection_handling":     grab(r"Handling\s+Objections\s*&\s*Answering\s*Queries"),
        "pricing_communication":  grab(r"Pricing\s*&\s*Value\s*Communication"),
        "trust_building":         grab(r"Trust\s*&\s*Confidence\s*Building"),
        "call_closure":           grab(r"Call\s*Closure\s*&\s*Next\s*Step\s*Commitment"),
    }
    logging.info(f"üìä Parsed Scores (regex fallback): {scores}")
    return scores

# ========== ROUTE ==========
@app.post("/generate-report")
async def generate_report_endpoint(request: Request):
    try:
        data = await request.json()
        file_id = data.get("file_id")
        if not file_id:
            return JSONResponse(status_code=400, content={"error": "Missing file_id"})

        mp3_path = download_mp3_from_drive(file_id)
        chunks = split_audio(mp3_path)

        parts: List[str] = []
        try:
            for p in chunks:
                parts.append(transcribe_audio(p))
        finally:
            # cleanup
            for p in chunks:
                try: os.remove(p)
                except: pass
            try: os.remove(mp3_path)
            except: pass

        full_transcript = clean_transcript(" ".join(parts).strip())
        raw_output = generate_openai_report(full_transcript)

        # 1) Try to extract JSON scores & strip from report (so PDF won't show JSON)
        scores, cleaned_report = extract_json_and_strip(raw_output)

        # 2) If JSON failed, fallback to regex; keep full text as report
        if scores is None:
            scores = parse_scores_from_report(raw_output)
            cleaned_report = raw_output

        return {"report": cleaned_report, "scores": scores}

    except Exception as e:
        logging.exception("‚ùå Report generation failed")
        return JSONResponse(status_code=500, content={"error": str(e)})
